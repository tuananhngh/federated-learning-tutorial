{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Building a Flower Client\n",
    "\n",
    "In this notebook, we'll learn:\n",
    "1. What is a Flower client?\n",
    "2. How to implement train and evaluate functions\n",
    "3. Understanding the client lifecycle\n",
    "4. Message passing in Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from flwr.app import ArrayRecord, ConfigRecord, Context, Message, MetricRecord, RecordDict\n",
    "from flwr.clientapp import ClientApp\n",
    "from fltutorial.task import Net, load_data, train as train_fn, test as test_fn\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is a Flower Client?\n",
    "\n",
    "In Flower's federated learning architecture:\n",
    "\n",
    "- **Client**: Trains the model on local data and sends updates to the server\n",
    "- **Server**: Coordinates the training process and aggregates model updates\n",
    "\n",
    "### Client Responsibilities:\n",
    "1. **Receive** global model parameters from server\n",
    "2. **Train** the model on local data\n",
    "3. **Send** updated model parameters back to server\n",
    "4. **Evaluate** the model on local test data (optional)\n",
    "\n",
    "### Communication Flow:\n",
    "```\n",
    "Server                          Client\n",
    "   │                              │\n",
    "   ├──── Send Model ────────────>│\n",
    "   │                              │ (Load model)\n",
    "   │                              │ (Train locally)\n",
    "   │                              │\n",
    "   │<──── Send Updates ───────────┤\n",
    "   │                              │\n",
    "   ├──── Request Eval ──────────>│\n",
    "   │                              │ (Evaluate)\n",
    "   │<──── Send Metrics ───────────┤\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding Flower Messages\n",
    "\n",
    "Flower uses **Messages** to communicate between server and clients.\n",
    "\n",
    "### Message Structure:\n",
    "```python\n",
    "Message(\n",
    "    content={\n",
    "        \"arrays\": ArrayRecord,    # Model weights\n",
    "        \"config\": ConfigRecord,   # Training config (lr, epochs, etc.)\n",
    "        \"metrics\": MetricRecord   # Metrics (loss, accuracy, etc.)\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "### Key Components:\n",
    "- **ArrayRecord**: Stores model parameters (weights, biases)\n",
    "- **ConfigRecord**: Training configuration (learning rate, batch size, etc.)\n",
    "- **MetricRecord**: Performance metrics (loss, accuracy, number of samples, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementing the Train Function\n",
    "\n",
    "The train function:\n",
    "1. Receives a message with global model weights\n",
    "2. Loads the model and sets the weights\n",
    "3. Trains on local data\n",
    "4. Returns updated weights and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ClientApp instance\n",
    "app = ClientApp()\n",
    "\n",
    "@app.train()\n",
    "def train(msg: Message, context: Context) -> Message:\n",
    "    \"\"\"Train the model on local data.\"\"\"\n",
    "    \n",
    "    # Extract message content\n",
    "    assert isinstance(msg.content[\"arrays\"], ArrayRecord)\n",
    "    assert isinstance(msg.content[\"config\"], ConfigRecord)\n",
    "    assert isinstance(msg.content[\"metrics\"], MetricRecord)\n",
    "    \n",
    "    print(\"\\n[CLIENT] Received training request\")\n",
    "    \n",
    "    # Load the model and initialize it with received weights\n",
    "    model = Net()\n",
    "    model.load_state_dict(msg.content[\"arrays\"].to_torch_state_dict())\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    print(f\"[CLIENT] Model loaded on {device}\")\n",
    "    \n",
    "    # Load local data\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "    batch_size = context.run_config[\"batch-size\"]\n",
    "    \n",
    "    if (\n",
    "        isinstance(partition_id, int)\n",
    "        and isinstance(num_partitions, int)\n",
    "        and isinstance(batch_size, int)\n",
    "    ):\n",
    "        trainloader, _ = load_data(partition_id, num_partitions, batch_size)\n",
    "        print(f\"[CLIENT] Loaded data for partition {partition_id}/{num_partitions}\")\n",
    "        print(f\"[CLIENT] Training samples: {len(trainloader.dataset)}\")\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"partition_id, num_partitions, and batch_size must be integers\"\n",
    "        )\n",
    "    \n",
    "    # Train the model\n",
    "    local_epochs = context.run_config[\"local-epochs\"]\n",
    "    learning_rate = msg.content[\"config\"][\"lr\"]\n",
    "    print(f\"[CLIENT] Training for {local_epochs} epochs with lr={learning_rate}\")\n",
    "    \n",
    "    train_loss = train_fn(\n",
    "        model,\n",
    "        trainloader,\n",
    "        local_epochs,\n",
    "        learning_rate,\n",
    "        device,\n",
    "    )\n",
    "    print(f\"[CLIENT] Training completed. Loss: {train_loss:.4f}\")\n",
    "    \n",
    "    # Construct reply message with updated model and metrics\n",
    "    model_record = ArrayRecord(model.state_dict())\n",
    "    metrics = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"num-examples\": len(trainloader.dataset),\n",
    "    }\n",
    "    metric_record = MetricRecord(metrics)\n",
    "    content = RecordDict({\"arrays\": model_record, \"metrics\": metric_record})\n",
    "    \n",
    "    print(f\"[CLIENT] Sending {metrics['num-examples']} examples back to server\\n\")\n",
    "    return Message(content=content, reply_to=msg)\n",
    "\n",
    "print(\"Train function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Implementing the Evaluate Function\n",
    "\n",
    "The evaluate function:\n",
    "1. Receives a message with model weights\n",
    "2. Evaluates the model on local test data\n",
    "3. Returns evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.evaluate()\n",
    "def evaluate(msg: Message, context: Context):\n",
    "    \"\"\"Evaluate the model on local data.\"\"\"\n",
    "    \n",
    "    # Extract message content\n",
    "    assert isinstance(msg.content[\"arrays\"], ArrayRecord)\n",
    "    assert isinstance(msg.content[\"config\"], ConfigRecord)\n",
    "    assert isinstance(msg.content[\"metrics\"], MetricRecord)\n",
    "    \n",
    "    print(\"\\n[CLIENT] Received evaluation request\")\n",
    "    \n",
    "    # Load the model and initialize it with received weights\n",
    "    model = Net()\n",
    "    model.load_state_dict(msg.content[\"arrays\"].to_torch_state_dict())\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Load local data\n",
    "    partition_id = context.node_config[\"partition-id\"]\n",
    "    num_partitions = context.node_config[\"num-partitions\"]\n",
    "    batch_size = context.run_config[\"batch-size\"]\n",
    "    \n",
    "    if (\n",
    "        isinstance(partition_id, int)\n",
    "        and isinstance(num_partitions, int)\n",
    "        and isinstance(batch_size, int)\n",
    "    ):\n",
    "        _, valloader = load_data(partition_id, num_partitions, batch_size)\n",
    "        print(f\"[CLIENT] Evaluating on partition {partition_id}\")\n",
    "        print(f\"[CLIENT] Test samples: {len(valloader.dataset)}\")\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"partition_id, num_partitions, and batch_size must be integers\"\n",
    "        )\n",
    "    \n",
    "    # Evaluate the model\n",
    "    eval_loss, eval_acc = test_fn(\n",
    "        model,\n",
    "        valloader,\n",
    "        device,\n",
    "    )\n",
    "    print(f\"[CLIENT] Evaluation completed.\")\n",
    "    print(f\"[CLIENT] Loss: {eval_loss:.4f}, Accuracy: {eval_acc*100:.2f}%\")\n",
    "    \n",
    "    # Construct reply message with metrics\n",
    "    metrics = {\n",
    "        \"eval_loss\": eval_loss,\n",
    "        \"eval_acc\": eval_acc,\n",
    "        \"num-examples\": len(valloader.dataset),\n",
    "    }\n",
    "    metric_record = MetricRecord(metrics)\n",
    "    content = RecordDict({\"metrics\": metric_record})\n",
    "    \n",
    "    print(f\"[CLIENT] Sending metrics back to server\\n\")\n",
    "    return Message(content=content, reply_to=msg)\n",
    "\n",
    "print(\"Evaluate function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Understanding the Client Lifecycle\n",
    "\n",
    "During a federated learning session, each client goes through multiple rounds:\n",
    "\n",
    "### Round Structure:\n",
    "```\n",
    "Round 1:\n",
    "  1. Receive global model from server\n",
    "  2. Train on local data (update weights)\n",
    "  3. Send updated weights to server\n",
    "  4. [Optional] Evaluate model on local test data\n",
    "  5. Send evaluation metrics to server\n",
    "\n",
    "Round 2:\n",
    "  1. Receive NEW global model (aggregated from all clients)\n",
    "  2. Train on local data\n",
    "  3. Send updated weights to server\n",
    "  4. ...\n",
    "  \n",
    "... (continue for N rounds)\n",
    "```\n",
    "\n",
    "### Key Points:\n",
    "- Each round starts with a **fresh global model** (not the local updated one)\n",
    "- Clients don't keep state between rounds\n",
    "- The server aggregates updates from ALL clients before next round"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizing Weight Updates\n",
    "\n",
    "Let's visualize how weights change during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a simple demonstration\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Initialize model\n",
    "model = Net()\n",
    "initial_weights = model.fc3.weight.data.clone()\n",
    "\n",
    "# Load data for one client\n",
    "from fltutorial.task import load_data\n",
    "trainloader, testloader = load_data(partition_id=0, num_partitions=5, batch_size=32)\n",
    "\n",
    "# Train for 1 epoch\n",
    "train_loss = train_fn(model, trainloader, epochs=1, lr=0.01, device=device)\n",
    "updated_weights = model.fc3.weight.data.clone()\n",
    "\n",
    "# Calculate the difference\n",
    "weight_diff = (updated_weights - initial_weights).abs()\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "im1 = axes[0].imshow(initial_weights.numpy(), cmap='viridis', aspect='auto')\n",
    "axes[0].set_title('Initial Weights (from server)')\n",
    "axes[0].set_xlabel('Input features')\n",
    "axes[0].set_ylabel('Output classes')\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "im2 = axes[1].imshow(updated_weights.numpy(), cmap='viridis', aspect='auto')\n",
    "axes[1].set_title('Updated Weights (after local training)')\n",
    "axes[1].set_xlabel('Input features')\n",
    "axes[1].set_ylabel('Output classes')\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "im3 = axes[2].imshow(weight_diff.numpy(), cmap='hot', aspect='auto')\n",
    "axes[2].set_title('Weight Updates (sent to server)')\n",
    "axes[2].set_xlabel('Input features')\n",
    "axes[2].set_ylabel('Output classes')\n",
    "plt.colorbar(im3, ax=axes[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average weight change: {weight_diff.mean():.6f}\")\n",
    "print(f\"Max weight change: {weight_diff.max():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. The Complete Client Code\n",
    "\n",
    "The complete client implementation is available in [src/fltutorial/client.py](../src/fltutorial/client.py).\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Stateless**: Clients don't maintain state between rounds\n",
    "2. **Message-Based**: All communication via Flower Messages\n",
    "3. **Flexible**: Can customize training logic, data loading, etc.\n",
    "4. **Privacy-Preserving**: Only model weights are shared, not raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we learned:\n",
    "1. ✅ What a Flower client is and its responsibilities\n",
    "2. ✅ How to implement train and evaluate functions\n",
    "3. ✅ Understanding message passing in Flower\n",
    "4. ✅ The client lifecycle and round structure\n",
    "5. ✅ Visualizing weight updates during training\n",
    "\n",
    "**Next Steps**: In Notebook 4, we'll learn how to build the server that coordinates all clients!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises for Students\n",
    "\n",
    "**Exercise 1**: What information is sent from client to server? What is NOT sent?\n",
    "\n",
    "**Exercise 2**: Why is it important that clients are stateless (don't keep info between rounds)?\n",
    "\n",
    "**Exercise 3**: Modify the code to track and plot the training loss over epochs within a single round.\n",
    "\n",
    "**Exercise 4**: What would happen if one client has much more data than others? How does FedAvg handle this?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
