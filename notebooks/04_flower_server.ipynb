{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 4: Building a Flower Server\n",
    "\n",
    "In this notebook, we'll learn:\n",
    "1. What is a Flower server?\n",
    "2. Understanding aggregation strategies (FedAvg)\n",
    "3. Implementing server logic\n",
    "4. Global model evaluation\n",
    "5. Saving the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from flwr.app import ArrayRecord, ConfigRecord, Context, MetricRecord\n",
    "from flwr.serverapp import Grid, ServerApp\n",
    "from flwr.serverapp.strategy import FedAvg\n",
    "from fltutorial.task import Net, load_centralized_dataset, test\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is a Flower Server?\n",
    "\n",
    "The server is the coordinator of federated learning:\n",
    "\n",
    "### Server Responsibilities:\n",
    "1. **Initialize** the global model\n",
    "2. **Select** clients for each round\n",
    "3. **Send** global model to selected clients\n",
    "4. **Receive** model updates from clients\n",
    "5. **Aggregate** updates using a strategy (e.g., FedAvg)\n",
    "6. **Evaluate** the global model (optional)\n",
    "7. **Save** the final model\n",
    "\n",
    "### Federated Learning Flow:\n",
    "```\n",
    "Server                      Clients\n",
    "  │                           │\n",
    "  ├─ Initialize model         │\n",
    "  │                           │\n",
    "  ├─ Round 1 ─────────────────┤\n",
    "  │  ├─ Select clients         │\n",
    "  │  ├─ Send model ──────────>│ (Train locally)\n",
    "  │  │                         │\n",
    "  │  │<─ Receive updates ──────┤\n",
    "  │  ├─ Aggregate (FedAvg)     │\n",
    "  │  └─ Evaluate               │\n",
    "  │                           │\n",
    "  ├─ Round 2 ─────────────────┤\n",
    "  │  ...                       │\n",
    "  │                           │\n",
    "  └─ Save final model         │\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding FedAvg Strategy\n",
    "\n",
    "**FedAvg** (Federated Averaging) is the most common aggregation strategy.\n",
    "\n",
    "### How FedAvg Works:\n",
    "\n",
    "1. **Receive Updates**: Get model weights from K clients\n",
    "   - Client 1: $w_1$, trained on $n_1$ samples\n",
    "   - Client 2: $w_2$, trained on $n_2$ samples\n",
    "   - ...\n",
    "   - Client K: $w_K$, trained on $n_K$ samples\n",
    "\n",
    "2. **Compute Weighted Average**:\n",
    "   $$w_{global} = \\frac{\\sum_{i=1}^{K} n_i \\cdot w_i}{\\sum_{i=1}^{K} n_i}$$\n",
    "\n",
    "3. **Update Global Model**: Set $w_{global}$ as the new global model\n",
    "\n",
    "### Why Weighted?\n",
    "- Clients with more data contribute more to the global model\n",
    "- Ensures fairness and better convergence\n",
    "- Handles heterogeneous data sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple demonstration of FedAvg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simulate 3 clients with different number of samples\n",
    "clients = [\n",
    "    {\"id\": 0, \"weight\": 2.5, \"samples\": 100},\n",
    "    {\"id\": 1, \"weight\": 3.0, \"samples\": 200},\n",
    "    {\"id\": 2, \"weight\": 1.5, \"samples\": 50},\n",
    "]\n",
    "\n",
    "# Simple average (incorrect)\n",
    "simple_avg = np.mean([c[\"weight\"] for c in clients])\n",
    "\n",
    "# Weighted average (FedAvg - correct)\n",
    "total_samples = sum(c[\"samples\"] for c in clients)\n",
    "weighted_avg = sum(c[\"weight\"] * c[\"samples\"] for c in clients) / total_samples\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart of weights\n",
    "client_ids = [c[\"id\"] for c in clients]\n",
    "weights = [c[\"weight\"] for c in clients]\n",
    "samples = [c[\"samples\"] for c in clients]\n",
    "\n",
    "ax1.bar(client_ids, weights, color=['lightblue', 'lightgreen', 'lightcoral'])\n",
    "ax1.axhline(y=simple_avg, color='red', linestyle='--', label=f'Simple avg: {simple_avg:.2f}')\n",
    "ax1.axhline(y=weighted_avg, color='green', linestyle='--', label=f'Weighted avg (FedAvg): {weighted_avg:.2f}')\n",
    "ax1.set_xlabel('Client ID')\n",
    "ax1.set_ylabel('Model Weight (example)')\n",
    "ax1.set_title('Client Weights')\n",
    "ax1.legend()\n",
    "ax1.set_xticks(client_ids)\n",
    "\n",
    "# Pie chart of sample distribution\n",
    "ax2.pie(samples, labels=[f'Client {i}\\n{s} samples' for i, s in zip(client_ids, samples)], \n",
    "        autopct='%1.1f%%', colors=['lightblue', 'lightgreen', 'lightcoral'])\n",
    "ax2.set_title('Data Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Simple average: {simple_avg:.4f}\")\n",
    "print(f\"Weighted average (FedAvg): {weighted_avg:.4f}\")\n",
    "print(f\"\\nClient 1 has more data (200 samples), so it influences the global model more!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implementing the Server\n",
    "\n",
    "Let's build the server step by step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ServerApp\n",
    "app = ServerApp()\n",
    "\n",
    "@app.main()\n",
    "def main(grid: Grid, context: Context) -> None:\n",
    "    \"\"\"Main entry point for the ServerApp.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"[SERVER] Starting Federated Learning Server\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Read configuration from context\n",
    "    fraction_evaluate: float = context.run_config[\"fraction-evaluate\"]\n",
    "    num_rounds: int = context.run_config[\"num-server-rounds\"]\n",
    "    lr: float = context.run_config[\"learning-rate\"]\n",
    "    \n",
    "    print(f\"[SERVER] Configuration:\")\n",
    "    print(f\"  - Number of rounds: {num_rounds}\")\n",
    "    print(f\"  - Learning rate: {lr}\")\n",
    "    print(f\"  - Fraction evaluate: {fraction_evaluate}\")\n",
    "    \n",
    "    # Initialize global model\n",
    "    print(f\"\\n[SERVER] Initializing global model...\")\n",
    "    global_model = Net()\n",
    "    arrays = ArrayRecord(global_model.state_dict())\n",
    "    print(f\"[SERVER] Global model initialized with {sum(p.numel() for p in global_model.parameters()):,} parameters\")\n",
    "    \n",
    "    # Initialize FedAvg strategy\n",
    "    print(f\"\\n[SERVER] Initializing FedAvg strategy...\")\n",
    "    strategy = FedAvg(fraction_evaluate=fraction_evaluate)\n",
    "    \n",
    "    # Start federated learning\n",
    "    print(f\"\\n[SERVER] Starting federated learning for {num_rounds} rounds...\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    result = strategy.start(\n",
    "        grid=grid,\n",
    "        initial_arrays=arrays,\n",
    "        train_config=ConfigRecord({\"lr\": lr}),\n",
    "        num_rounds=num_rounds,\n",
    "        evaluate_fn=global_evaluate,\n",
    "    )\n",
    "    \n",
    "    # Save final model\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"[SERVER] Federated learning completed!\")\n",
    "    print(\"[SERVER] Saving final model to disk...\")\n",
    "    state_dict = result.arrays.to_torch_state_dict()\n",
    "    torch.save(state_dict, \"final_model.pt\")\n",
    "    print(\"[SERVER] Model saved as 'final_model.pt'\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "print(\"Server main function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Global Model Evaluation\n",
    "\n",
    "The server can evaluate the global model on a centralized test set:\n",
    "\n",
    "### Why Global Evaluation?\n",
    "- **Monitor Progress**: Track how the global model improves over rounds\n",
    "- **Early Stopping**: Stop training if model converges\n",
    "- **Fair Comparison**: Evaluate on same data across all rounds\n",
    "\n",
    "### When to Evaluate?\n",
    "- After each round of aggregation\n",
    "- On a centralized test set (not distributed to clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_evaluate(server_round: int, arrays: ArrayRecord) -> MetricRecord:\n",
    "    \"\"\"Evaluate model on central test data.\"\"\"\n",
    "    \n",
    "    print(f\"\\n[SERVER] Round {server_round}: Evaluating global model...\")\n",
    "    \n",
    "    # Load the model and initialize with received weights\n",
    "    model = Net()\n",
    "    model.load_state_dict(arrays.to_torch_state_dict())\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Load entire test set\n",
    "    test_dataloader = load_centralized_dataset()\n",
    "    \n",
    "    # Evaluate the global model\n",
    "    test_loss, test_acc = test(model, test_dataloader, device)\n",
    "    \n",
    "    print(f\"[SERVER] Round {server_round}: Loss={test_loss:.4f}, Accuracy={test_acc*100:.2f}%\")\n",
    "    \n",
    "    # Return the evaluation metrics\n",
    "    return MetricRecord({\"accuracy\": test_acc, \"loss\": test_loss})\n",
    "\n",
    "print(\"Global evaluate function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Understanding the Grid\n",
    "\n",
    "The **Grid** is Flower's abstraction for managing clients:\n",
    "\n",
    "### Grid Responsibilities:\n",
    "- **Client Discovery**: Find available clients\n",
    "- **Client Selection**: Choose which clients participate in each round\n",
    "- **Communication**: Handle message passing between server and clients\n",
    "- **Fault Tolerance**: Handle client failures gracefully\n",
    "\n",
    "### Client Selection Strategies:\n",
    "1. **All clients**: Use all available clients (default)\n",
    "2. **Random sampling**: Randomly select a fraction of clients\n",
    "3. **Custom selection**: Implement custom logic based on client properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Server Configuration\n",
    "\n",
    "The server uses configuration parameters from `context.run_config`:\n",
    "\n",
    "### Common Parameters:\n",
    "- `num-server-rounds`: Number of federated learning rounds\n",
    "- `learning-rate`: Learning rate for client training\n",
    "- `fraction-evaluate`: Fraction of clients to use for evaluation\n",
    "- `local-epochs`: Number of local training epochs per round\n",
    "- `batch-size`: Batch size for training\n",
    "\n",
    "These parameters are typically set in a configuration file or command-line arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Tracking Training Progress\n",
    "\n",
    "Let's visualize what happens during federated learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate federated learning progress\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simulated metrics over 10 rounds\n",
    "rounds = list(range(1, 11))\n",
    "loss = [2.3, 1.8, 1.4, 1.1, 0.9, 0.8, 0.7, 0.65, 0.62, 0.60]\n",
    "accuracy = [10, 35, 52, 65, 72, 77, 80, 82, 83, 84]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot loss\n",
    "ax1.plot(rounds, loss, marker='o', linewidth=2, markersize=8, color='red')\n",
    "ax1.set_xlabel('Round', fontsize=12)\n",
    "ax1.set_ylabel('Test Loss', fontsize=12)\n",
    "ax1.set_title('Global Model Loss Over Rounds', fontsize=14)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot accuracy\n",
    "ax2.plot(rounds, accuracy, marker='s', linewidth=2, markersize=8, color='green')\n",
    "ax2.set_xlabel('Round', fontsize=12)\n",
    "ax2.set_ylabel('Test Accuracy (%)', fontsize=12)\n",
    "ax2.set_title('Global Model Accuracy Over Rounds', fontsize=14)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(0, 100)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Notice how:\")\n",
    "print(\"- Loss decreases over rounds (model is learning)\")\n",
    "print(\"- Accuracy increases over rounds\")\n",
    "print(\"- Improvement slows down in later rounds (convergence)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. The Complete Server Code\n",
    "\n",
    "The complete server implementation is available in [src/fltutorial/server.py](../src/fltutorial/server.py).\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Coordinator**: Server orchestrates the entire training process\n",
    "2. **Aggregation**: Uses FedAvg to combine client updates\n",
    "3. **Evaluation**: Tracks global model performance\n",
    "4. **Stateful**: Server maintains the global model across rounds\n",
    "5. **Configurable**: Behavior controlled by configuration parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we learned:\n",
    "1. ✅ What a Flower server is and its responsibilities\n",
    "2. ✅ Understanding the FedAvg aggregation strategy\n",
    "3. ✅ Implementing server logic with ServerApp\n",
    "4. ✅ Global model evaluation\n",
    "5. ✅ Tracking training progress over rounds\n",
    "\n",
    "**Next Steps**: In Notebook 5, we'll run the complete federated learning experiment with multiple clients!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises for Students\n",
    "\n",
    "**Exercise 1**: Why do we use weighted averaging instead of simple averaging in FedAvg?\n",
    "\n",
    "**Exercise 2**: What would happen if we didn't evaluate the global model? How would we know if training is working?\n",
    "\n",
    "**Exercise 3**: Research: What are some alternative aggregation strategies besides FedAvg? (Hint: FedProx, FedAdam)\n",
    "\n",
    "**Exercise 4**: If one client sends corrupted updates, how might it affect the global model? How could we detect this?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
