{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Introduction to Federated Learning\n",
    "\n",
    "Welcome to the Frugal AI Federated Learning Tutorial!\n",
    "\n",
    "## What is Federated Learning?\n",
    "\n",
    "Federated Learning (FL) is a machine learning technique that trains models across multiple decentralized devices or servers holding local data samples, without exchanging the raw data itself.\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "1. **Privacy-Preserving**: Raw data never leaves the local device\n",
    "2. **Decentralized Training**: Multiple clients train on their local data\n",
    "3. **Model Aggregation**: A central server aggregates model updates\n",
    "4. **Iterative Process**: Training happens over multiple rounds\n",
    "\n",
    "### The Federated Learning Process:\n",
    "\n",
    "```\n",
    "1. Server initializes a global model\n",
    "2. Server sends the model to selected clients\n",
    "3. Each client trains the model on its local data\n",
    "4. Clients send model updates back to the server\n",
    "5. Server aggregates updates to create a new global model\n",
    "6. Repeat steps 2-5 for multiple rounds\n",
    "```\n",
    "\n",
    "## Why Federated Learning?\n",
    "\n",
    "### Advantages:\n",
    "- **Privacy**: Sensitive data remains on local devices\n",
    "- **Reduced Communication**: Only model updates are transmitted\n",
    "- **Scalability**: Can leverage computation from many devices\n",
    "- **Regulatory Compliance**: Helps with GDPR and data protection laws\n",
    "\n",
    "### Challenges:\n",
    "- **Non-IID Data**: Data on different clients may be distributed differently\n",
    "- **Communication Costs**: Network latency and bandwidth limitations\n",
    "- **System Heterogeneity**: Different devices have different capabilities\n",
    "- **Privacy Attacks**: Still vulnerable to inference attacks\n",
    "\n",
    "## Flower Framework\n",
    "\n",
    "In this tutorial, we use **Flower** (https://flower.ai/), a friendly federated learning framework that makes it easy to implement FL systems.\n",
    "\n",
    "### Key Components:\n",
    "- **Client**: Trains the model on local data\n",
    "- **Server**: Coordinates training and aggregates model updates\n",
    "- **Strategy**: Defines how model updates are aggregated (e.g., FedAvg)\n",
    "\n",
    "Let's verify our environment is set up correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check installed packages\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "import flwr\n",
    "print(f\"Flower version: {flwr.__version__}\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"\\nAll required packages are installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated Averaging (FedAvg)\n",
    "\n",
    "The most common aggregation strategy is **FedAvg** (Federated Averaging):\n",
    "\n",
    "### Algorithm:\n",
    "1. Each client trains on local data and computes weight updates\n",
    "2. Server collects all weight updates\n",
    "3. Server computes weighted average based on number of samples:\n",
    "\n",
    "$$w_{global} = \\frac{\\sum_{i=1}^{K} n_i \\cdot w_i}{\\sum_{i=1}^{K} n_i}$$\n",
    "\n",
    "where:\n",
    "- $K$ is the number of clients\n",
    "- $n_i$ is the number of samples on client $i$\n",
    "- $w_i$ are the weights from client $i$\n",
    "\n",
    "Let's simulate a simple averaging process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple demonstration of federated averaging\n",
    "import numpy as np\n",
    "\n",
    "# Simulate 3 clients with different model parameters\n",
    "client1_weights = np.array([1.0, 2.0, 3.0])\n",
    "client1_samples = 100\n",
    "\n",
    "client2_weights = np.array([1.5, 2.5, 3.5])\n",
    "client2_samples = 200\n",
    "\n",
    "client3_weights = np.array([0.5, 1.5, 2.5])\n",
    "client3_samples = 150\n",
    "\n",
    "# Compute weighted average (FedAvg)\n",
    "total_samples = client1_samples + client2_samples + client3_samples\n",
    "global_weights = (\n",
    "    client1_weights * client1_samples +\n",
    "    client2_weights * client2_samples +\n",
    "    client3_weights * client3_samples\n",
    ") / total_samples\n",
    "\n",
    "print(\"Client 1 weights:\", client1_weights, f\"({client1_samples} samples)\")\n",
    "print(\"Client 2 weights:\", client2_weights, f\"({client2_samples} samples)\")\n",
    "print(\"Client 3 weights:\", client3_weights, f\"({client3_samples} samples)\")\n",
    "print(\"\\nGlobal aggregated weights:\", global_weights)\n",
    "print(\"\\nNotice how the global weights are closer to Client 2's weights,\")\n",
    "print(\"since it has more samples (200) than the others.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Tutorial Project\n",
    "\n",
    "In this tutorial series, we will:\n",
    "\n",
    "1. **Understand the Dataset**: Explore CIFAR-10 and data partitioning\n",
    "2. **Build the Model**: Create a CNN for image classification\n",
    "3. **Implement Clients**: Write Flower clients that train locally\n",
    "4. **Implement Server**: Create a server that aggregates updates\n",
    "5. **Run Experiments**: Execute federated learning with multiple clients\n",
    "\n",
    "### Dataset: CIFAR-10\n",
    "- 60,000 32x32 color images\n",
    "- 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
    "- We'll partition it across multiple clients\n",
    "\n",
    "### Model: Simple CNN\n",
    "- 2 convolutional layers\n",
    "- 3 fully connected layers\n",
    "- ~62,000 parameters\n",
    "\n",
    "Ready to continue? Move on to **Notebook 2** to explore the dataset and model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise for Students\n",
    "\n",
    "**Question 1**: What are the main advantages of Federated Learning compared to centralized training?\n",
    "\n",
    "**Question 2**: Why is data heterogeneity (non-IID data) a challenge in federated learning?\n",
    "\n",
    "**Question 3**: In FedAvg, why do we use weighted averaging based on the number of samples instead of simple averaging?\n",
    "\n",
    "**Bonus**: Research and name one real-world application where federated learning is currently being used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
